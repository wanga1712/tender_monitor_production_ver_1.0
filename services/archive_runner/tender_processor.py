"""
MODULE: services.archive_runner.tender_processor
RESPONSIBILITY: Orchestrate processing of a single tender (download, extract, match, save).
ALLOWED: TenderMatchRepository, FolderManager, DocumentSelector, Downloader, Extractor, MatchFinder, logging, FileValidator.
FORBIDDEN: Direct DB queries (use repositories).
ERRORS: DocumentSearchError.

–ú–æ–¥—É–ª—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–¥–µ—Ä–∞.
"""

from __future__ import annotations

import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from loguru import logger

from core.exceptions import DocumentSearchError
from services.document_search.document_selector import DocumentSelector
from services.document_search.document_downloader import DocumentDownloader
from services.document_search.archive_extractor import ArchiveExtractor
from services.document_search.match_finder import MatchFinder
from services.match_services.tender_match_repository_facade import TenderMatchRepositoryFacade
from services.archive_runner.tender_folder_manager import TenderFolderManager
from services.archive_runner.file_cleaner import FileCleaner
from services.archive_runner.processed_tenders_repository import ProcessedTendersRepository
from services.archive_runner.tender_prefetcher import PrefetchedTenderData
from services.archive_runner.document_download_manager import DocumentDownloadManager
from services.archive_runner.workbook_manager import WorkbookManager
from services.archive_runner.match_executor import MatchExecutor
from services.archive_runner.result_saver import ResultSaver
from services.archive_runner.file_validator import FileValidator


class TenderProcessor:
    """–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–¥–µ—Ä–∞."""

    def __init__(
        self,
        tender_match_repo: TenderMatchRepository,
        folder_manager: TenderFolderManager,
        document_search_service,
        selector: DocumentSelector,
        downloader: DocumentDownloader,
        extractor: ArchiveExtractor,
        match_finder: MatchFinder,
        file_cleaner: FileCleaner,
        processed_tenders_repo: Optional[ProcessedTendersRepository] = None,
        max_workers: int = 2,
        safe_call_func=None,
        get_avg_time_func=None,
        batch_delay: float = 5.0,
    ):
        self.folder_manager = folder_manager
        self.file_cleaner = file_cleaner
        self.selector = selector
        self.downloader = downloader
        self._safe_call = safe_call_func
        self.processed_tenders_repo = processed_tenders_repo

        self.download_manager = DocumentDownloadManager(downloader, max_workers)
        self.workbook_manager = WorkbookManager(selector, extractor, downloader)
        # –ü–µ—Ä–µ–¥–∞–µ–º batch_delay –¥–ª—è –ø–∞—É–∑ –º–µ–∂–¥—É –ø–∞—Ä—Ç–∏—è–º–∏ —Ñ–∞–π–ª–æ–≤
        self.match_executor = MatchExecutor(match_finder, max_workers, get_avg_time_func, batch_delay)
        self.result_saver = ResultSaver(tender_match_repo, safe_call_func)
        self.file_validator = FileValidator(
            self.workbook_manager, 
            self.downloader, 
            self.processed_tenders_repo
        )

    def process_tender(
        self,
        tender: Dict[str, Any],
        documents: Optional[List[Dict[str, Any]]] = None,
        existing_records: Optional[List[Dict[str, Any]]] = None,
        get_tender_documents_func=None,
        prefetched_data: Optional[PrefetchedTenderData] = None,
        processed_tenders_cache: Optional[Dict] = None,
        tender_type: str = 'new',
    ) -> Optional[Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–¥–µ—Ä–∞.
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏
        """
        tender_id = tender.get("id")
        registry_type = tender.get("registry_type", "44fz")
        tender_name = tender.get("auction_name", f"–¢–æ—Ä–≥ #{tender_id}")

        # #region agent log PROCESS_TENDER_START
        import json
        import time as time_module
        log_path = Path(__file__).parent.parent.parent / ".cursor" / "debug.log"
        try:
            with open(log_path, "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "sessionId": "debug-session",
                    "runId": "analysis-trigger",
                    "hypothesisId": "process-start",
                    "location": "tender_processor.py:process_tender",
                    "message": "PROCESS_TENDER_START",
                    "data": {
                        "tender_id": tender_id,
                        "registry_type": registry_type,
                        "tender_type": tender_type,
                        "has_documents": documents is not None,
                        "documents_count": len(documents) if documents else 0
                    },
                    "timestamp": int(time_module.time() * 1000)
                }, ensure_ascii=False) + "\n")
        except Exception:
            pass
        # #endregion
        
        folder_path = prefetched_data.folder_path if prefetched_data else self.folder_manager.prepare_tender_folder(tender_id, registry_type, tender_type)
        folder_name = folder_path.name if folder_path else f"{registry_type}_{tender_id}_{tender_type}"
        tender["folder_path"] = folder_path

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ —ç—Ç–∞ —Ç–æ—Ä–≥ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ –∏–º—è –ø–∞–ø–∫–∏ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ —Ç–∏–ø–∞ —Ç–æ—Ä–≥–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        base_folder_name = f"{registry_type}_{tender_id}"
        if self.processed_tenders_repo and self.processed_tenders_repo.is_tender_processed(tender_id, registry_type, base_folder_name):
            # #region agent log IS_TENDER_PROCESSED
            try:
                log_path = Path(__file__).parent.parent.parent / ".cursor" / "debug.log"
                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps({
                        "sessionId": "debug-session",
                        "runId": "analysis-trigger",
                        "hypothesisId": "is-processed-check",
                        "location": "tender_processor.py:process_tender:is_processed",
                        "message": "IS_TENDER_PROCESSED_TRUE",
                        "data": {
                            "tender_id": tender_id,
                            "registry_type": registry_type,
                            "base_folder_name": base_folder_name
                        },
                        "timestamp": int(time_module.time() * 1000)
                    }, ensure_ascii=False) + "\n")
            except Exception:
                pass
            # #endregion
            logger.debug(f"‚è≠Ô∏è –¢–æ—Ä–≥ {tender_id} ({registry_type}) —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return None

        # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ advisory-lock –æ—Ç–∫–ª—é—á–µ–Ω—ã –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö –∏ —Ä–∞–∑—ã–≥—Ä–∞–Ω–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤
        # –ù–æ–≤—ã–µ –∏ —Ä–∞–∑—ã–≥—Ä–∞–Ω–Ω—ã–µ —Ç–æ—Ä–≥–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –≤ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
        
        logger.debug(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}, {tender_type})")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤ (–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–∞—Ç—á–µ–º –≤ runner.py)
        # –ï—Å–ª–∏ —Ç–µ–Ω–¥–µ—Ä–∞ –Ω–µ—Ç –≤ –∫—ç—à–µ, –∑–Ω–∞—á–∏—Ç –æ–Ω –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω - –Ω–µ –¥–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ –ë–î
        match_result = None
        if processed_tenders_cache:
            match_result = processed_tenders_cache.get((tender_id, registry_type))
        
        # –ï—Å–ª–∏ —Ç–µ–Ω–¥–µ—Ä–∞ –Ω–µ—Ç –≤ –∫—ç—à–µ, –∑–Ω–∞—á–∏—Ç –æ–Ω –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ –ë–î
        # –ö—ç—à —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–æ—Ä–≥–∏ (–∑–∞–≥—Ä—É–∂–µ–Ω—ã –±–∞—Ç—á–µ–º)
        if match_result:
            # #region agent log
            import json
            import os
            # Path —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
            project_root = Path(__file__).parent.parent.parent
            log_path = project_root / ".cursor" / "debug.log"
            log_path.parent.mkdir(parents=True, exist_ok=True)
            try:
                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps({
                        "sessionId": "debug-session",
                        "runId": "run1",
                        "hypothesisId": "H",
                        "location": "tender_processor.py:process_tender:already_processed",
                        "message": "–¢–æ—Ä–≥ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º",
                        "data": {
                            "tender_id": tender_id,
                            "registry_type": registry_type,
                            "match_count": match_result.get("match_count", 0),
                            "processed_at": str(match_result.get("processed_at", "unknown")),
                            "is_interesting": match_result.get("is_interesting")
                        },
                        "timestamp": int(time_module.time() * 1000)
                    }, ensure_ascii=False) + "\n")
            except Exception:
                pass
            # #endregion
            
            self._log_already_processed(tender_id, registry_type, match_result)
            return self.result_saver.create_skipped_result(
                tender_id, registry_type, "already_processed", match_result
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–æ—Ä–≥ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω)
        # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –í–°–ï–ì–î–ê, –¥–∞–∂–µ –¥–ª—è prefetched —Ñ–∞–π–ª–æ–≤,
        # —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –æ–Ω–∏ –Ω–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç–∫—Ä—ã—Ç—ã/—Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω—ã
        try:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ ‚Äî —Å—á–∏—Ç–∞–µ–º –∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if prefetched_data and prefetched_data.download_records:
                documents = prefetched_data.download_records
                logger.debug(
                    f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}), "
                    f"files={len(documents)}"
                )

            existing_records = None
            if documents:
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∫–∞—á–∞–Ω–Ω—ã—Ö (prefetch –∏–ª–∏ —Ä–∞–Ω–µ–µ) —Ñ–∞–π–ª–æ–≤
                valid_records = self.file_validator.validate_prefetched_files(
                    documents, 
                    folder_path,
                    tender_id,
                    registry_type,
                    folder_name,
                    tender.get("user_id", 1)
                )
                if valid_records is None:
                    logger.warning(
                        f"–í—Å–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}), –æ—á–∏—â–∞–µ–º –ø–∞–ø–∫—É"
                    )
                    self.folder_manager.clean_tender_folder_force(folder_path)
                    documents = None
                elif len(valid_records) < len(documents):
                    logger.warning(
                        f"–ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}), —É–¥–∞–ª—è–µ–º –∏—Ö –∏–∑ —Å–ø–∏—Å–∫–∞"
                    )
                    documents = valid_records
                    existing_records = valid_records
                else:
                    existing_records = valid_records
                    logger.info(f"–°–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤–∞–ª–∏–¥–Ω—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö")

            if not documents and not (prefetched_data and prefetched_data.cleaned):
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ prefetch ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–∞–ª–∏–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
                existing_records = self.file_validator.check_existing_files(folder_path)
                if existing_records is None:
                    logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}), –æ—á–∏—â–∞–µ–º –ø–∞–ø–∫—É")
                    self.folder_manager.clean_tender_folder_force(folder_path)
                    existing_records = None
                elif existing_records:
                    logger.info(f"–ù–∞–π–¥–µ–Ω—ã –≤–∞–ª–∏–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö")

            documents = documents or (prefetched_data.documents if prefetched_data else None)
            if documents is None and get_tender_documents_func:
                documents = get_tender_documents_func(tender_id, registry_type)

            # #region agent log DOCUMENTS_RESOLVED
            try:
                log_path = Path(__file__).parent.parent.parent / ".cursor" / "debug.log"
                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps({
                        "sessionId": "debug-session",
                        "runId": "analysis-trigger",
                        "hypothesisId": "docs-resolved",
                        "location": "tender_processor.py:process_tender:documents_resolved",
                        "message": "DOCUMENTS_RESOLVED",
                        "data": {
                            "tender_id": tender_id,
                            "registry_type": registry_type,
                            "has_prefetched_data": prefetched_data is not None,
                            "prefetched_docs_count": len(prefetched_data.documents) if prefetched_data and prefetched_data.documents else 0,
                            "prefetched_records_count": len(prefetched_data.download_records) if prefetched_data and prefetched_data.download_records else 0,
                            "documents_count": len(documents) if documents else 0,
                            "existing_records_count": len(existing_records) if existing_records else 0
                        },
                        "timestamp": int(time_module.time() * 1000)
                    }, ensure_ascii=False) + "\n")
            except Exception:
                pass
            # #endregion

            # –°—Ç—Ä–æ–∏–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è/–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            # –ï—Å–ª–∏ –µ—Å—Ç—å existing_records (–≤–∞–ª–∏–¥–Ω—ã–µ —Ñ–∞–π–ª—ã), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º prefetched_data.download_records (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –∏ –≤–∞–ª–∏–¥–Ω—ã)
            download_records = self._build_download_records(existing_records, prefetched_data)
            if not download_records and documents:
                try:
                    selected_docs = self.selector.choose_documents(documents)
                    unique_docs = self.selector.group_documents_by_archive(selected_docs, documents)
                    download_records = self.download_manager.download_documents(unique_docs, documents, folder_path)
                except DocumentSearchError as error:
                    logger.warning(f"–î–ª—è —Ç–æ—Ä–≥–∞ {tender_id} –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {error}")

            if not download_records:
                logger.warning(f"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ —Ç–æ—Ä–≥—É {tender_id} ({registry_type}) - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –ë–î")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –ë–î –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                folder_name = folder_path.name if folder_path and folder_path.exists() else (f"{registry_type}_{tender_id}_won" if tender_type == 'won' else f"{registry_type}_{tender_id}")
                
                return self.result_saver.save_error_result(
                    tender_id,
                    registry_type,
                    error_reason="no_documents",
                    folder_name=folder_name,
                    processing_time=time.time() - processing_start
                )

            logger.info(f"\n{'=' * 80}")
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ—Ä–≥–∞: {tender_name} (ID: {tender_id}, {registry_type})")
            logger.info(f"{'=' * 80}")
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è/–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {len(download_records)}")
            
            # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            if download_records:
                total_files = sum(len(record.get("paths", [])) for record in download_records)
                logger.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –∑–∞–ø–∏—Å—è—Ö: {total_files}")
                for idx, record in enumerate(download_records[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –∑–∞–ø–∏—Å–∏
                    paths = record.get("paths", [])
                    logger.debug(f"  –ó–∞–ø–∏—Å—å {idx+1}: {len(paths)} —Ñ–∞–π–ª–æ–≤, –ø—É—Ç–∏: {[str(p)[-50:] for p in paths[:2]]}")

            processing_start = time.time()
            logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}...")

            # #region agent log
            import json
            project_root = Path(__file__).parent.parent.parent
            log_path = project_root / ".cursor" / "debug.log"

            try:
                with open(str(log_path), "a", encoding="utf-8") as f:
                    f.write(json.dumps({
                        "sessionId": "debug-session",
                        "runId": "analysis",
                        "hypothesisId": "ANALYSIS",
                        "location": "tender_processor.py:process_tender:before_prepare_paths",
                        "message": "–ü–µ—Ä–µ–¥ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–æ–π –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º",
                        "data": {
                            "tender_id": tender_id,
                            "registry_type": registry_type,
                            "download_records_count": len(download_records),
                            "folder_path": str(folder_path) if folder_path else None
                        },
                        "timestamp": int(time_module.time() * 1000)
                    }, ensure_ascii=False) + "\n")
                    f.flush()
            except Exception:
                pass
            # #endregion
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: —É–¥–∞–ª—è–µ–º, —Å–∫–∞—á–∏–≤–∞–µ–º –∑–∞–Ω–æ–≤–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º
            download_records = self.file_validator.handle_corrupted_files(download_records, documents, folder_path)

            # #region agent log
            import json
            import os
            project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            log_path = os.path.join(project_root, ".cursor", "debug.log")
            try:
                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps({
                        "sessionId": "debug-session",
                        "runId": "doc-processing-debug",
                        "hypothesisId": "BEFORE_PREPARE_PATHS",
                        "location": "tender_processor.py:process_tender:before_prepare_paths",
                        "message": f"–ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º prepare_workbook_paths –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}",
                        "data": {
                            "tender_id": tender_id,
                            "registry_type": registry_type,
                            "download_records_count": len(download_records),
                            "folder_path": str(folder_path)
                        },
                        "timestamp": int(time_module.time() * 1000)
                    }))
            except Exception as e:
                pass
            # #endregion
            
            try:
                workbook_paths, archive_paths, excel_paths = self.workbook_manager.prepare_workbook_paths(
                    download_records,
                    documents,
                    folder_path,
                )
                logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –ø—É—Ç–µ–π: workbook={len(workbook_paths) if workbook_paths else 0}, archive={len(archive_paths) if archive_paths else 0}, excel={len(excel_paths) if excel_paths else 0}")

                # #region agent log
                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "analysis",
                            "hypothesisId": "ANALYSIS",
                            "location": "tender_processor.py:process_tender:after_prepare_paths",
                            "message": "–ü–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "workbook_paths_count": len(workbook_paths) if workbook_paths else 0,
                                "archive_paths_count": len(archive_paths) if archive_paths else 0,
                                "excel_paths_count": len(excel_paths) if excel_paths else 0
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                        f.flush()
                except Exception:
                    pass
                # #endregion

            except Exception as prep_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}: {prep_error}", exc_info=True)
                folder_name = folder_path.name if folder_path and folder_path.exists() else (f"{registry_type}_{tender_id}_won" if tender_type == 'won' else f"{registry_type}_{tender_id}")

                return self.result_saver.save_error_result(
                    tender_id,
                    registry_type,
                    error_reason=f"prepare_paths_error: {str(prep_error)[:200]}",
                    error_message=f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—É—Ç–µ–π: {prep_error}",
                    folder_name=folder_name,
                    processing_time=time.time() - processing_start
                )
            
            if not workbook_paths:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å Excel —Ñ–∞–π–ª—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type})")
                logger.error(f"   download_records: {len(download_records)} –∑–∞–ø–∏—Å–µ–π")
                if download_records:
                    total_files = sum(len(record.get("paths", [])) for record in download_records)
                    logger.error(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –∑–∞–ø–∏—Å—è—Ö: {total_files}")
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –ø–µ—Ä–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
                    for idx, record in enumerate(download_records[:5]):
                        paths = record.get("paths", [])
                        logger.error(f"   –ó–∞–ø–∏—Å—å {idx+1}: {len(paths)} —Ñ–∞–π–ª–æ–≤")
                        for path_idx, path in enumerate(paths[:3]):
                            path_obj = Path(path)
                            exists = path_obj.exists()
                            logger.error(f"      –§–∞–π–ª {path_idx+1}: {path_obj.name} (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {exists}, —Ä–∞–∑–º–µ—Ä: {path_obj.stat().st_size if exists else 0})")
                logger.error(f"   –ü–∞–ø–∫–∞ —Ç–æ—Ä–≥–∞: {folder_path} (—Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {folder_path.exists()})")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –ë–î –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                folder_name = folder_path.name if folder_path and folder_path.exists() else (f"{registry_type}_{tender_id}_won" if tender_type == 'won' else f"{registry_type}_{tender_id}")

                return self.result_saver.save_error_result(
                    tender_id,
                    registry_type,
                    error_reason="no_workbook_files",
                    error_message=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å Excel —Ñ–∞–π–ª—ã: {len(download_records)} –∑–∞–ø–∏—Å–µ–π, {sum(len(r.get('paths', [])) for r in download_records)} —Ñ–∞–π–ª–æ–≤",
                    folder_name=folder_name,
                    processing_time=time.time() - processing_start
                )
            
            logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {len(workbook_paths)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}...")
            if workbook_paths:
                logger.info(f"   –ü—Ä–∏–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤: {[p.name for p in workbook_paths[:3]]}")
            
            # #region agent log
            import json
            import os
            # Path —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
            project_root = Path(__file__).parent.parent.parent
            log_path = project_root / ".cursor" / "debug.log"
            log_path.parent.mkdir(parents=True, exist_ok=True)
            try:
                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(json.dumps({
                        "sessionId": "debug-session",
                        "runId": "run1",
                        "hypothesisId": "F",
                        "location": "tender_processor.py:process_tender:before_match_executor",
                        "message": "–ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º match_executor.run",
                        "data": {
                            "tender_id": tender_id,
                            "registry_type": registry_type,
                            "workbook_paths_count": len(workbook_paths),
                            "workbook_paths": [str(p) for p in workbook_paths[:5]],
                            "folder_path": str(folder_path) if folder_path else None
                        },
                        "timestamp": int(time_module.time() * 1000)
                    }, ensure_ascii=False) + "\n")
            except Exception:
                pass
            # #endregion

            try:
                logger.debug(f"–ó–∞–ø—É—Å–∫ match_executor.run() –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} —Å {len(workbook_paths)} —Ñ–∞–π–ª–∞–º–∏")

                # #region agent log - –î–û–°–¢–£–ü –î–û MATCH_EXECUTOR
                import json
                project_root = Path(__file__).parent.parent.parent
                log_path = project_root / ".cursor" / "debug.log"

                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "analysis",
                            "hypothesisId": "ANALYSIS",
                            "location": "tender_processor.py:process_tender:reached_match_executor",
                            "message": "–î–û–°–¢–ò–ì–õ–ò –≤—ã–∑–æ–≤–∞ match_executor.run",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "workbook_paths_count": len(workbook_paths),
                                "workbook_paths_sample": [str(p)[-50:] for p in workbook_paths[:3]] if workbook_paths else []
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                        f.flush()
                except Exception:
                    pass
                # #endregion

                # #region agent log
                import json
                import os
                log_path = r"c:\Users\wangr\PycharmProjects\pythonProject89\.cursor\debug.log"
                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "run1",
                            "hypothesisId": "B",
                            "location": "tender_processor.py:process_tender:before_match_executor",
                            "message": "–ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º match_executor.run",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "workbook_paths_count": len(workbook_paths)
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                        f.flush()
                        os.fsync(f.fileno())
                except Exception:
                    pass
                # #endregion
                
                match_result = self.match_executor.run(workbook_paths)
                matches = match_result.get("matches", [])
                failed_files = match_result.get("failed_files", [])
                
                # #region agent log
                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.flush()
                        os.fsync(f.fileno())
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "run1",
                            "hypothesisId": "B",
                            "location": "tender_processor.py:process_tender:after_match_executor",
                            "message": "–ü–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ match_executor.run",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "matches_count": len(matches) if matches else 0,
                                "failed_files_count": len(failed_files),
                                "matches_is_none": matches is None,
                                "matches_is_empty": matches == [] if matches is not None else None,
                                "sample_matches": [{"product": m.get("product"), "score": m.get("score")} for m in (matches[:3] if matches else [])]
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                except Exception:
                    pass
                # #endregion
                
                logger.info(f"üîç Match executor –≤–µ—Ä–Ω—É–ª {len(matches) if matches else 0} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}")
                if matches:
                    examples = [f"{m.get('product', 'N/A')} ({m.get('score', 0):.1f}%)" for m in matches[:3]]
                    logger.info(f"   –ü—Ä–∏–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {examples}")
                if failed_files:
                    logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(failed_files)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}")
                    for failed_file in failed_files[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        logger.warning(f"   - {Path(failed_file['path']).name}: {failed_file['error'][:100]}")
                processing_elapsed = time.time() - processing_start
                logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–î –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}...")
                
                # #region agent log
                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.flush()
                        os.fsync(f.fileno())
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "run1",
                            "hypothesisId": "F",
                            "location": "tender_processor.py:process_tender:after_match_executor",
                            "message": "–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è match_executor.run",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "matches_count": len(matches) if matches else 0,
                                "processing_elapsed": processing_elapsed
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                except Exception:
                    pass
                # #endregion
                # #region agent log
                import json
                import os
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å (Path —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ)
                project_root = Path(__file__).parent.parent.parent
                log_path = project_root / ".cursor" / "debug.log"
                log_path.parent.mkdir(parents=True, exist_ok=True)
                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.flush()
                        os.fsync(f.fileno())
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "run1",
                            "hypothesisId": "F",
                            "location": "tender_processor.py:process_tender:before_save",
                            "message": "–ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º result_saver.save",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "matches_count": len(matches) if matches else 0,
                                "files_count": len(workbook_paths)
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                except Exception:
                    pass
                # #endregion
                
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –î–û —É–¥–∞–ª–µ–Ω–∏—è (–ø–æ–∫–∞ –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
                folder_name = None
                if folder_path and folder_path.exists():
                    folder_name = folder_path.name
                else:
                    # –ï—Å–ª–∏ –ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ñ–æ—Ä–º–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —è–≤–Ω–æ
                    if tender_type == 'won':
                        folder_name = f"{registry_type}_{tender_id}_won"
                    else:
                        folder_name = f"{registry_type}_{tender_id}"
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î —Å folder_name –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
                result = self.result_saver.save(
                    tender_id, 
                    registry_type, 
                    matches, 
                    workbook_paths, 
                    processing_elapsed, 
                    error_reason=None, 
                    folder_name=folder_name,
                    failed_files=failed_files
                )
                
                if result is None:
                    # #region agent log - SAVE FAILED
                    try:
                        with open(str(log_path), "a", encoding="utf-8") as f:
                            f.write(json.dumps({
                                "sessionId": "debug-session",
                                "runId": "save-failure",
                                "hypothesisId": "SAVE_FAILED",
                                "location": "tender_processor.py:save_result_failure",
                                "message": "–ö–†–ò–¢–ò–ß–ù–ê–Ø –û–®–ò–ë–ö–ê: result_saver.save –≤–µ—Ä–Ω—É–ª None",
                                "data": {
                                    "tender_id": tender_id,
                                    "registry_type": registry_type,
                                    "matches_count": len(matches),
                                    "files_count": len(workbook_paths),
                                    "processing_elapsed": processing_elapsed,
                                    "match_percentage": result.get("match_percentage") if result else None
                                },
                                "timestamp": int(time_module.time() * 1000)
                            }, ensure_ascii=False) + "\n")
                            f.flush()
                            os.fsync(f.fileno())
                    except Exception:
                        pass
                    # #endregion

                # #region agent log
                try:
                    with open(str(log_path), "a", encoding="utf-8") as f:
                        f.flush()
                        os.fsync(f.fileno())
                        f.write(json.dumps({
                            "sessionId": "debug-session",
                            "runId": "run1",
                            "hypothesisId": "F",
                            "location": "tender_processor.py:process_tender:after_save",
                            "message": "–ü–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ result_saver.save",
                            "data": {
                                "tender_id": tender_id,
                                "registry_type": registry_type,
                                "result": result is not None,
                                "match_count": result.get("match_count") if result else None
                            },
                            "timestamp": int(time_module.time() * 1000)
                        }, ensure_ascii=False) + "\n")
                except Exception:
                    pass
                # #endregion
                
                logger.debug(f"Result saver –≤–µ—Ä–Ω—É–ª –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}: {result}")

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
                match_count = len(matches) if matches else 0
                if match_count > 0:
                    logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {match_count} (–≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_elapsed:.1f} —Å–µ–∫)")
                else:
                    logger.info(f"‚ö†Ô∏è –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_elapsed:.1f} —Å–µ–∫)")

                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã –∏ –ø–∞–ø–∫—É —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–ø–∏—Å–∏ –≤ –ë–î (–Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ —É–¥–∞–ª–µ–Ω–∏–µ)
                # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã –ù–ï —É–¥–∞–ª—è–µ–º - –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                if result is not None:
                    if failed_files:
                        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}, —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ {len(failed_files)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö)")
                    else:
                        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}, —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã –∏ –ø–∞–ø–∫—É")
                    try:
                        self.file_cleaner.cleanup_all_files(
                            archive_paths,
                            workbook_paths,
                            extraction_success=True,
                            db_save_success=True,
                            failed_files=failed_files,
                        )
                        # –£–¥–∞–ª—è–µ–º –≤—Å—é –ø–∞–ø–∫—É —Ç–æ—Ä–≥–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                        if folder_path and folder_path.exists():
                            if failed_files:
                                logger.info(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ —Ç–æ—Ä–≥–∞ {tender_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (—Å–æ–¥–µ—Ä–∂–∏—Ç {len(failed_files)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤)")
                            else:
                                try:
                                    logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ –ø–∞–ø–∫–∏ —Ç–æ—Ä–≥–∞ {tender_id} –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {folder_path.name}")
                                    self.folder_manager.clean_tender_folder_force(folder_path)
                                    # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å —Å–∞–º—É –ø–∞–ø–∫—É
                                    try:
                                        folder_path.rmdir()
                                        logger.debug(f"–ü–∞–ø–∫–∞ {folder_path.name} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞")
                                    except OSError:
                                        # –ü–∞–ø–∫–∞ –Ω–µ –ø—É—Å—Ç–∞ –∏–ª–∏ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, —Ñ–∞–π–ª—ã —É–∂–µ —É–¥–∞–ª–µ–Ω—ã
                                        logger.debug(f"–ü–∞–ø–∫–∞ {folder_path.name} –Ω–µ –ø—É—Å—Ç–∞ –∏–ª–∏ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ")
                                except Exception as folder_cleanup_error:
                                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É —Ç–æ—Ä–≥–∞ {tender_id}: {folder_cleanup_error}")
                    except Exception as cleanup_error:
                        # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}: {cleanup_error}")
                else:
                    # –ï—Å–ª–∏ result_saver.save() –≤–µ—Ä–Ω—É–ª None, —ç—Ç–æ –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
                    logger.error(
                        f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}). "
                        f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {match_count}, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å."
                    )
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ—à–∏–±–∫–µ –≤–º–µ—Å—Ç–æ None
                    return {
                        "tender_id": tender_id,
                        "registry_type": registry_type,
                        "match_count": match_count,
                        "match_percentage": 0.0,
                        "error": True,
                        "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î",
                        "error_saved": False,
                    }
                
                return result
            except Exception as processing_error:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π time –º–æ–¥—É–ª—å (–∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞)
                processing_elapsed = time.time() - processing_start
                error_message = str(processing_error)
                logger.error(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}): {error_message}",
                    exc_info=True  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π traceback
                )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –ë–î –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –î–û —É–¥–∞–ª–µ–Ω–∏—è (–ø–æ–∫–∞ –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
                folder_name = None
                if folder_path and folder_path.exists():
                    folder_name = folder_path.name
                else:
                    # –ï—Å–ª–∏ –ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ñ–æ—Ä–º–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —è–≤–Ω–æ
                    if tender_type == 'won':
                        folder_name = f"{registry_type}_{tender_id}_won"
                    else:
                        folder_name = f"{registry_type}_{tender_id}"
                
                error_result = self.result_saver.save(
                    tender_id,
                    registry_type,
                    [],
                    workbook_paths,
                    processing_elapsed,
                    error_reason=f"processing_error: {error_message[:200]}",  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
                    folder_name=folder_name,
                )
                return {
                    "tender_id": tender_id,
                    "registry_type": registry_type,
                    "match_count": 0,
                    "match_percentage": 0.0,
                    "error": True,
                    "error_message": error_message,
                    "error_saved": error_result is not None,
                }
        except Exception as critical_error:
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê - –≤—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å –∏ –∫—Ä–∞—à–∏–º —Å–∏—Å—Ç–µ–º—É
            import traceback
            import sys
            
            error_msg = f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type})"
            error_details = str(critical_error)
            full_traceback = traceback.format_exc()
            
            # –í—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å (stderr –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞)
            print("\n" + "="*80, file=sys.stderr)
            print(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê", file=sys.stderr)
            print("="*80, file=sys.stderr)
            print(f"{error_msg}: {error_details}", file=sys.stderr)
            print("\n–ü–æ–ª–Ω—ã–π traceback:", file=sys.stderr)
            print(full_traceback, file=sys.stderr)
            print("="*80 + "\n", file=sys.stderr)
            sys.stderr.flush()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ logger
            logger.critical(
                f"{error_msg}: {error_details}",
                exc_info=True
            )
            
            # –ö—Ä–∞—à–∏–º —Å–∏—Å—Ç–µ–º—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            sys.exit(1)


    def _build_download_records(
        self,
        existing_records: Optional[List[Dict[str, Any]]],
        prefetched_data: Optional[PrefetchedTenderData],
    ) -> List[Dict[str, Any]]:
        # Delegate to file_validator if needed, but it's simple enough here.
        # Actually, FileValidator has this method now too.
        return self.file_validator.build_download_records(existing_records, prefetched_data)

    @staticmethod
    def _log_already_processed(tender_id: int, registry_type: str, match_result: Dict[str, Any]) -> None:
        logger.info(
            f"–¢–æ—Ä–≥ {tender_id} ({registry_type}) —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π {match_result.get('match_count', 0)}, —Ñ–∞–π–ª–æ–≤ {match_result.get('total_files_processed', 0)}, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {match_result.get('processed_at') or '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}"
        )
        logger.info(
            f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}). –î–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–¥–∞–ª–∏—Ç–µ –∑–∞–ø–∏—Å—å –∏–∑ tender_document_matches."
        )

